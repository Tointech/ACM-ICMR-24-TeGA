{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQXeQ6AGi9hI"
      },
      "source": [
        "## **1. Init**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jjjtBhsjWTv"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# TODO: Specify the path to the JSON file\n",
        "json_file_path = \"sd_pairs.json\"\n",
        "\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    loaded_pairs = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK0xaKZhmHJH"
      },
      "source": [
        "## **2. Compute Contextual Deviation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjuwVxpL7f20"
      },
      "source": [
        "### **Setup environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZfH3jCk7ffF"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUMV3eJN73sa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEKcYXRO7OoU"
      },
      "source": [
        "### **Use CLIP to encode image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYfFPoic7G-M"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPModel, CLIPProcessor\n",
        "\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHpswNfI8ET8"
      },
      "source": [
        "### **Calculate deviation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQFx2kF27R-L"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(image1, image2):\n",
        "    image_tensor1 = clip_processor(images=image1, return_tensors=\"pt\").to(device)\n",
        "    image_tensor2 = clip_processor(images=image2, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    image_feature1 = clip_model.get_image_features(image_tensor1.pixel_values)\n",
        "    image_feature2 = clip_model.get_image_features(image_tensor2.pixel_values)\n",
        "\n",
        "    similarity = torch.nn.functional.cosine_similarity(image_feature1, image_feature2, dim=-1)\n",
        "\n",
        "    return similarity.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV8RsrWR7xLU"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "for i, pair in enumerate(loaded_pairs):\n",
        "    original_image = Image.open(loaded_pairs[i][1])\n",
        "    generated_image = Image.open(loaded_pairs[i][4])\n",
        "\n",
        "    similarity_score = cosine_similarity(original_image, generated_image)\n",
        "    deviation_value = 1 - similarity_score\n",
        "\n",
        "    pair.append(deviation_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea57fg7i9B6r"
      },
      "outputs": [],
      "source": [
        "# TODO: Specify the path where you want to save the JSON file\n",
        "json_file_path = \"sd_deviation.json\"\n",
        "\n",
        "with open(json_file_path, 'w') as json_file:\n",
        "    json.dump(loaded_pairs, json_file)\n",
        "\n",
        "print(f\"Deviation saved to {json_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoKemKIsELc2"
      },
      "source": [
        "## **3. Context-Matching Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIp5Tf9rfaED"
      },
      "source": [
        "### **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPQoYPCW_gaO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# TODO: Specify the path to the JSON file\n",
        "json_file_path = \"sd_deviation.json\"\n",
        "\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    pairs = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "risjRchbEbs4"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i, pair in enumerate(pairs):\n",
        "      if type(pairs[i][5]) is float:\n",
        "          X.append(pairs[i][5])\n",
        "          y.append(pairs[i][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwCPc8v0WtFF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'Label': y, 'Deviation Value': X})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA3W-rnkauTZ"
      },
      "source": [
        "### **3.1 Train in whole data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzhbtR2wbDcW"
      },
      "source": [
        "#### **Split into training and validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFOHk6BhbCur"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "label_mapping = {'NOOC': 0, 'OOC': 1}\n",
        "y = np.array([label_mapping[label] for label in y])\n",
        "X = np.array(X).reshape(-1, 1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-xBHnbMelpW"
      },
      "source": [
        "#### **Test algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjeyFfnmd2yF"
      },
      "source": [
        "##### **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmAueH1xd5bM"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "predictions = svm_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJK5UfqYEM3S"
      },
      "source": [
        "##### **ANN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBoWqWTjEM3T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4ITyVY8Z5ls"
      },
      "source": [
        "### **3.2 Train in mean set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ODCR7BWfx09"
      },
      "source": [
        "#### **Calculate mean**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o5jcH35The8"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "sets_data = defaultdict(lambda: {'sum': 0, 'count': 0, 'label': ''})\n",
        "\n",
        "for sublist in pairs:\n",
        "    identifier = sublist[0]\n",
        "    label = sublist[3]\n",
        "\n",
        "    if label in ['OOC', 'NOOC']:\n",
        "        value = sublist[-1]\n",
        "        sets_data[identifier]['sum'] += value\n",
        "        sets_data[identifier]['count'] += 1\n",
        "        sets_data[identifier]['label'] = label\n",
        "\n",
        "means = {identifier: {'mean': data['sum'] / data['count'] if data['count'] > 0 else 0, 'label': data['label']} for identifier, data in sets_data.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uDrlDeIUBHm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_mean = []\n",
        "y = []\n",
        "\n",
        "for identifier, data in sets_data.items():\n",
        "    mean_value = data['sum'] / data['count'] if data['count'] > 0 else 0\n",
        "    label = data['label']\n",
        "\n",
        "    X_mean.append(mean_value)\n",
        "    y.append(label)\n",
        "\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZU44CssL2oV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'Label': y, 'Deviation Value': X_mean})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh8m0SLtGZ0b"
      },
      "source": [
        "#### **Split into training and validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG_RNOZdGLNE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "label_mapping = {'NOOC': 0, 'OOC': 1}\n",
        "y = np.array([label_mapping[label] for label in y])\n",
        "X = np.array(X_mean).reshape(-1, 1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTFi5ke-f9KT"
      },
      "source": [
        "#### **Test algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqZPSTPWhEiA"
      },
      "source": [
        "##### **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q1yMz6fhG-l"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "predictions = svm_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **ANN**"
      ],
      "metadata": {
        "id": "6qGQyvnkJ4fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "nn_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "1EeTd51pJ5_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtgwzruXTKn1"
      },
      "source": [
        "### **Save model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QVkSFPBNQsI"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(svm_model, 'context_matching_model.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xQXeQ6AGi9hI",
        "VjuwVxpL7f20",
        "GEKcYXRO7OoU",
        "VzhbtR2wbDcW",
        "z-xBHnbMelpW",
        "sjeyFfnmd2yF",
        "SJK5UfqYEM3S"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
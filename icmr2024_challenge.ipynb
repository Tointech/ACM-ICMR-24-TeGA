{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcH2Kn7MXFGB"
      },
      "source": [
        "# **I. Init & Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6IzasfA1ppi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "INPUT_FOLDER = \".\" # TODO: Fill the input path\n",
        "test_file = f\"{INPUT_FOLDER}/test.json\" # TODO: Change the test file if needed\n",
        "\n",
        "test_data = []\n",
        "\n",
        "with open(test_file, 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            json_obj = json.loads(line)\n",
        "            test_data.append(json_obj)\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Skipping invalid JSON: {line.strip()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snjmofgT2O4w"
      },
      "source": [
        "## **1. Pre-processing test data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pEu0ek643Km"
      },
      "source": [
        "### **Delete unrelated data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMWP6vjS4rnh"
      },
      "outputs": [],
      "source": [
        "modified_data = []\n",
        "\n",
        "for json_obj in test_data:\n",
        "    # For task 1\n",
        "    if 'article_url' in json_obj:\n",
        "        del json_obj['article_url']\n",
        "    if 'entity_list' in json_obj:\n",
        "        del json_obj['entity_list']\n",
        "    if 'caption1_modified' in json_obj:\n",
        "        del json_obj['caption1_modified']\n",
        "    if 'caption1_entities' in json_obj:\n",
        "        del json_obj['caption1_entities']\n",
        "    if 'caption2_modified' in json_obj:\n",
        "        del json_obj['caption2_modified']\n",
        "    if 'caption2_entities' in json_obj:\n",
        "        del json_obj['caption2_entities']\n",
        "    if 'maskrcnn_bboxes' in json_obj:\n",
        "        del json_obj['maskrcnn_bboxes']\n",
        "    if 'bert_base_score' in json_obj:\n",
        "        del json_obj['bert_base_score']\n",
        "    if 'bert_large_score' in json_obj:\n",
        "        del json_obj['bert_large_score']\n",
        "\n",
        "    # For task 2\n",
        "    if 'caption_modified' in json_obj:\n",
        "        del json_obj['caption_modified']\n",
        "    if 'caption_entities' in json_obj:\n",
        "        del json_obj['caption_entities']\n",
        "\n",
        "    modified_data.append(json_obj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2yl0HJd6_3Z"
      },
      "source": [
        "### **Normalize data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF6bElfr6VUs"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "for data_dict in modified_data:\n",
        "    # For task 1\n",
        "    if 'caption1' in data_dict:\n",
        "        data_dict['caption1'] = re.sub(r'[^a-zA-Z0-9.\\s]', '', data_dict['caption1'])\n",
        "    if 'caption2' in data_dict:\n",
        "        data_dict['caption2'] = re.sub(r'[^a-zA-Z0-9.\\s]', '', data_dict['caption2'])\n",
        "\n",
        "    # For task 2\n",
        "    if 'caption' in data_dict:\n",
        "        data_dict['caption'] = re.sub(r'[^a-zA-Z0-9.\\s]', '', data_dict['caption'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXbrxZxq9PSC"
      },
      "source": [
        "## **2. Setup Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZGmvlKl-F_y"
      },
      "outputs": [],
      "source": [
        "pair = modified_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68w0fzSU9c-t"
      },
      "source": [
        "### **Stable Diffusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTfTKX0S9R9c"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch diffusers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVkg3cOy9uqc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwHXC4Cg90n9"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "sd_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    \"nitrosocke/Ghibli-Diffusion\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    safety_checker = None,\n",
        "    requires_safety_checker = False).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6GmXO_lBMQ"
      },
      "source": [
        "### **Compute Deviation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg4ZdxQ9lHvt"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPModel, CLIPProcessor\n",
        "\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpMYyh-_lQp8"
      },
      "outputs": [],
      "source": [
        "def compute_deviation(image1, image2):\n",
        "    image_tensor1 = clip_processor(images=image1, return_tensors=\"pt\").to(device)\n",
        "    image_tensor2 = clip_processor(images=image2, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    image_feature1 = clip_model.get_image_features(image_tensor1.pixel_values)\n",
        "    image_feature2 = clip_model.get_image_features(image_tensor2.pixel_values)\n",
        "\n",
        "    similarity = torch.nn.functional.cosine_similarity(image_feature1, image_feature2, dim=-1)\n",
        "    deviation_value = 1 - similarity.item()\n",
        "\n",
        "    return deviation_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47DFzJshWSmz"
      },
      "source": [
        "### **NLI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUaP6jr9Xk6I"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "nli_model.to(device)\n",
        "\n",
        "def nli(string1, string2):\n",
        "    inputs = tokenizer(string1, string2, truncation=True, return_tensors=\"pt\")\n",
        "    inputs.to(device)\n",
        "\n",
        "    outputs = nli_model(**inputs)\n",
        "    prediction = torch.softmax(outputs.logits[0], -1).tolist()\n",
        "\n",
        "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
        "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOaJ9ztglX25"
      },
      "source": [
        "### **Load pre-trained Context-Matching model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1vn6O2ci9y-"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "context_matching = joblib.load('models/context_matching_model.pkl')\n",
        "\n",
        "def deviation_predict(X):\n",
        "    return context_matching.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ML4KznAfYSD"
      },
      "source": [
        "### **Save File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4CLBca0fivG"
      },
      "outputs": [],
      "source": [
        "def save_file(data_list, file_path):\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        for item in data_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "    print(f'The list has been saved to {file_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKQQ4xgTk6IN"
      },
      "source": [
        "## **3. Main Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q17YYqTlexh"
      },
      "source": [
        "#### **Task 1 Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxeMM0Eu-qJ9"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "def task1(item):\n",
        "    generator = torch.Generator(device=device).manual_seed(1024)\n",
        "    img_path = item['img_local_path']\n",
        "    original_image = Image.open(img_path)\n",
        "    original_image = original_image.resize((512, 512))\n",
        "\n",
        "    caption1 = item['caption1']\n",
        "    caption2 = item['caption2']\n",
        "\n",
        "    generated_image_1 = sd_pipe(prompt=caption1, image=original_image, strength=0.75, guidance_scale=7.5, generator=generator).images[0]\n",
        "    deviation_value_1 = compute_deviation(original_image, generated_image_1)\n",
        "    deviation_value_1 = np.array(deviation_value_1).reshape(-1, 1)\n",
        "    label_1 = deviation_predict(deviation_value_1)\n",
        "\n",
        "    generated_image_2 = sd_pipe(prompt=caption2, image=original_image, strength=0.75, guidance_scale=7.5, generator=generator).images[0]\n",
        "    deviation_value_2 = compute_deviation(original_image, generated_image_2)\n",
        "    deviation_value_2 = np.array(deviation_value_2).reshape(-1, 1)\n",
        "    label_2 = deviation_predict(deviation_value_2)\n",
        "\n",
        "    # Condition\n",
        "    if (label_1 + label_2 == 0):\n",
        "        label = 0\n",
        "        return label\n",
        "    else:\n",
        "        label = 1\n",
        "        return label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dwQBoC9ceDO"
      },
      "source": [
        "#### **Task 2 Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48JpAtvZcg1K"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "def task2(item):\n",
        "    generator = torch.Generator(device=device).manual_seed(1024)\n",
        "    img_path = item['img_local_path']\n",
        "    original_image = Image.open(img_path)\n",
        "    original_image = original_image.resize((512, 512))\n",
        "\n",
        "    caption = item['caption']\n",
        "\n",
        "    generated_image = sd_pipe(prompt=caption, image=original_image, strength=0.75, guidance_scale=7.5, generator=generator).images[0]\n",
        "    deviation_value = compute_deviation(original_image, generated_image)\n",
        "    deviation_value = np.array(deviation_value).reshape(-1, 1)\n",
        "    label = deviation_predict(deviation_value)[0]\n",
        "\n",
        "    return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHpO2f2yTZm"
      },
      "source": [
        "#### **Test Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_lR1YXdmYHW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "import time\n",
        "\n",
        "def test_task1(pair):\n",
        "    prediction_list = []\n",
        "    true_labels = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i, item in enumerate(pair):\n",
        "        caption1 = item['caption1']\n",
        "        caption2 = item['caption2']\n",
        "        context_label = item['context_label']\n",
        "\n",
        "        nli_result = nli(caption1, caption2)\n",
        "\n",
        "        if nli_result['entailment'] >= 80:\n",
        "            prediction = 0\n",
        "        else:\n",
        "            prediction = task1(item)\n",
        "\n",
        "        prediction_list.append(prediction)\n",
        "        true_labels.append(context_label)\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, prediction_list)\n",
        "    average_precision = average_precision_score(true_labels, prediction_list)\n",
        "    f1 = f1_score(true_labels, prediction_list)\n",
        "\n",
        "    print(\"Execution time:\", execution_time)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Average Precision:\", average_precision)\n",
        "    print(\"F1-Score:\", f1)\n",
        "\n",
        "    return prediction_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoRzdM-cetbo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "import time\n",
        "\n",
        "def test_task2(pair):\n",
        "    prediction_list = []\n",
        "    true_labels = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i, item in enumerate(pair):\n",
        "        caption = item['caption']\n",
        "        context_label = item['context_label']\n",
        "\n",
        "        prediction = task2(item)\n",
        "\n",
        "        prediction_list.append(prediction)\n",
        "        true_labels.append(context_label)\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, prediction_list)\n",
        "    average_precision = average_precision_score(true_labels, prediction_list)\n",
        "    f1 = f1_score(true_labels, prediction_list)\n",
        "\n",
        "    print(\"Execution time:\", execution_time)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Average Precision:\", average_precision)\n",
        "    print(\"F1-Score:\", f1)\n",
        "\n",
        "    return prediction_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHHQXbGo0zuh"
      },
      "source": [
        "# **II. Execute**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaBTno3CeW_O"
      },
      "source": [
        "*TODO: Execute here for Task 1*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJHKhqHLpo0c"
      },
      "outputs": [],
      "source": [
        "prediction_list = test_task1(pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XkpuBLegBpb"
      },
      "outputs": [],
      "source": [
        "output_file = \"task1.txt\"\n",
        "\n",
        "save_file(prediction_list, output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ANaZABMen84"
      },
      "source": [
        "*TODO: Execute here for Task 2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocADPwSLerX4"
      },
      "outputs": [],
      "source": [
        "prediction_list = test_task2(pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhwmQshugVtY"
      },
      "outputs": [],
      "source": [
        "output_file = \"task2.txt\"\n",
        "\n",
        "save_file(prediction_list, output_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
